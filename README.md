# Derm1M: A Millionâ€‘Scale Visionâ€‘Language Dataset Aligned with Clinical Ontology Knowledge for Dermatology
[![ArXiv](https://img.shields.io/badge/arXiv-2503.14911-b31b1b)](https://arxiv.org/abs/2503.14911)
[![License](https://img.shields.io/badge/License-CC%20BY--NC%204.0-green)](#ğŸ›¡ï¸-license)
[![Cite](https://img.shields.io/badge/Cite-BibTeX-blue)](#ğŸ“š-citation)

> âš ï¸ **Repo under construction**
> Weights, training & inference scripts, and dataset access will be released upon paper acceptance.

## âœ¨ TL;DR

**Derm1M** brings **1,029,761 dermatological imageâ€“text pairs** -257Ã— more than any previous dermatology visionâ€‘language corpusâ€”covering **390 skin conditions** and **130 clinical concepts** organised in a fourâ€‘level expert ontology. The datasetâ€™s rich contextual captions (meanâ€¯=â€¯41â€¯tokens) include metadata and other clinical contexts, enabling explainable multimodal learning, zeroâ€‘/fewâ€‘shot diagnosis, crossâ€‘modal retrieval, and visual question answering in realistic settings.

## ğŸ“¦ Whatâ€™s inside?

| Aspect                                                      | Derm1M                                                                                                  |
| ----------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| Total pairs                                                 | **1,029,761**                                                                                           |
ï½œUnique images                                               ï½œ**403,563**                                                                                              ï½œ
ï½œCaption breakdown                                           ï½œ**Refined medical (403â€¯563), Ontologyâ€‘based (403â€¯563), Conceptâ€‘based (222â€¯635)**                         ï½œ
| Skin conditions                                             | **390** (4 hierarchy levels)                                                                            |
| Clinical concepts                                           | **130**                                                                                                 |
| Avg. caption length                                         | **41 words**                                                                                            |
| Image sources                                               | YouTube (51â€¯k vids), PubMed (566â€¯k figs), Medical forums (49â€¯k posts), Public datasets, Teaching slide                                                                                
| Ontology                                                    | Structured JSONÂ + graph (disease â‡Œ concept â‡Œ finding)                                                   |

## ğŸ”‘ Key Features

* **Scale that matters** â€“ 1â€¯M+ image-text pairs enable training CLIPâ€‘style vision-language models for dermatology.
* **Comprehensive coverage** â€“ 390 conditions span inflammatory, infectious, neoplastic, and genodermatoses, mirroring realâ€‘world prevalence.
* **Rich context & concepts** â€“ Descriptions embed metadata and 130 physicianâ€‘understandable concepts for trustworthy reasoning.
* **Expertâ€‘curated ontology** â€“ Four boardâ€‘certified dermatologists built a hierarchical ontology to supervise multiâ€‘granular learning.
* **Benchmarkâ€‘ready splits** â€“ Standard benchmark comprising 8 downstream datasets for plugâ€‘andâ€‘play evaluation.

## ğŸ—ï¸ Repository Layout

```text
dataset_root/
â”œâ”€â”€ images/                # JPEG & PNG images
â”œâ”€â”€ captions.csv          # text + meta per image
â”œâ”€â”€ ontology.json          # disease & concept hierarchy
â”œâ”€â”€ splits/                # train/val indices
```

## ğŸš€ Preâ€‘trained Models: **DermLIP**

We provide two CLIPâ€‘style checkpoints trained from scratch on **Derm1M**:

| Model ID            | Vision Encoder | Text Encoder | Zeroâ€‘shot Avgâ€  | R\@10 Iâ†’T (holdâ€‘out) |
| ------------------- | -------------- | ------------ | -------------- | -------------------- |
| **DermLIPâ€‘B/16**    | ViTâ€‘B/16       | GPT77        | 56.1â€¯%         | 40.7â€¯%               |
| **DermLIPâ€‘PanDerm** | PanDermâ€‘B      | PMB256       | **58.8â€¯%**     | **59.9â€¯%**           |



## ğŸ“Š Key Benchmarks

| Task                                       | Metric    | DermLIPâ€‘PanDerm |  Best Prior SOTA  |       Î”      |
| :----------------------------------------- | :-------- | :-------------: | :---------------: | :----------: |
| Zeroâ€‘shot classification (avg. 4 datasets) | Accuracy  |    **58.8â€¯%**   | BiomedCLIP 44.1â€¯% | **+14.7â€¯pp** |
| Fewâ€‘shot (1â€¯% labels) linear probe         | Accuracy  |    **58.6â€¯%**   |    MONET 53.0â€¯%   |  **+5.6â€¯pp** |
| Crossâ€‘modal retrieval (SkinCAP)            | R\@10 Iâ†’T |    **20.2â€¯%**   |    MONET 14.2â€¯%   |  **+6.0â€¯pp** |

*All metrics are taken directly from TablesÂ 2â€“4 of the Derm1M paper.*

## ğŸ’¾ Data Access

The dataset is undergoing final review and will be released for **nonâ€‘commercial research under CCÂ BYâ€‘NCâ€‘4.0**. Join the [waitâ€‘list](https://forms.gle/derm1mâ€‘access) or watch this repo for updates.

## ğŸ“ Getting Started

```bash
git clone https://github.com/SiyuanYan1/Derm1M.git
conda env create -f environment.yml
```


## ğŸ“š Citation

If you find our work useful, please cite:

```bibtex
@misc{yan2025derm1m,
  title        = {Derm1M: A Millionâ€‘Scale Visionâ€‘Language Dataset Aligned with Clinical Ontology Knowledge for Dermatology},
  author       = {Siyuan Yan and Ming Hu and Yiwen Jiang and Xieji Li and Hao Fei and Philipp Tschandl and Harald Kittler and Zongyuan Ge},
  year         = {2025},
  eprint       = {2503.14911},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  url          = {https://arxiv.org/abs/2503.14911}
}
```

## ğŸ›¡ï¸ License

Derm1M is released under the **Creative Commons Attributionâ€‘NonCommercial 4.0 International** license. Commercial use requires separate permission.

## ğŸ™ Acknowledgements

We thank the


